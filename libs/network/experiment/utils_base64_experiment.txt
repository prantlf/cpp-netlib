Benchmark results from GCC 4.6.4 with the -O3 optimization:

1. Executing base64_from_message_test:
     Encoding 160 MB buffer took 1.68s.
2. Executing base64_stateless_test:
     Encoding 160 MB buffer took 4.25s.
3. Executing base64_stateful_buffer_test:
     Encoding 160 MB buffer took 5.11s.
     Encoding 1280 x 320 KB buffers took 12.85s.
4. Executing base64_stateful_transform_test:
     Encoding 160 MB buffer took 4.64s.
     Encoding 1280 x 320 KB buffers took 11.68s.
5. Executing base64_stateful_iterator_test:
     Encoding 160 MB buffer took 4.82s.
     Encoding 1280 x 320 KB buffers took 11.66s.
6. Executing base64_standalone_test:
     Encoding 160 MB buffer took 2.03s.
     Encoding 1280 x 320 KB buffers took 5.65s.
7. Executing base64_test:
     Encoding 160 MB buffer took 2.01s.
     Encoding 1280 x 320 KB buffers took 5.63s.
8. Executing base64_io_test:
     Encoding 160 MB buffer took 3.75s.
     Encoding 1280 x 320 KB buffers took 9.97s.

Testing the base64_from_message was done for the sake of completeness
just to test the internal implementation in the cpp-netlib.  Testing
the base64_stateless was done from the same reason; to test the pure
boost implementation alone; both implementations lack the state handling
and are not suitable for chunked encoding.

The three different base64_stateful_xxx implementations are comparable;
the base64_stateful_iterator may have spent more time in copy constructors,
because the state is owned lower - by the transformed iterator adaptor.
The iostream interface brings noticeable overhead, especially if the
encoding state (stored in the internal extensible array of the output stream)
is used extensively.

The boost transforming iterators are not enough to implement BASE64 encoding
of a chunked input.  Taking the additional code into consideration, the amount
of code for the non-boost base64_standalone implementation is not so different
and offers better performance.
